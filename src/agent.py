import logging
import os
import json
from datetime import datetime

from dotenv import load_dotenv
from src.utils import read_text
from livekit.agents import (
    NOT_GIVEN,
    Agent,
    AgentFalseInterruptionEvent,
    AgentSession,
    JobContext,
    JobProcess,
    MetricsCollectedEvent,
    RoomInputOptions,
    RoomOutputOptions,  # ‚Üê –¥–æ–±–∞–≤–∏–ª–∏
    RunContext,
    WorkerOptions,
    cli,
    metrics,
)
# from livekit.agents.llm import function_tool  # –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω–æ
from livekit.plugins import azure, noise_cancellation, openai, silero
from livekit.plugins.turn_detector.multilingual import MultilingualModel
from livekit.plugins.azure.tts import StyleConfig, ProsodyConfig

# üîΩ –¥–æ–±–∞–≤–∏–ª–∏ –∏–º–ø–æ—Ä—Ç –Ω–∞—à–∏—Ö —Ç—É–ª–∑–æ–≤
from tools.weather import lookup_weather
from tools.barber import load_barber_db, get_services, get_price, get_open_hours, list_staff, get_staff_day

logger = logging.getLogger("agent")

load_dotenv(".env.local")


class Assistant(Agent):
    def __init__(self) -> None:
        super().__init__(
            instructions=read_text("prompts/system.txt", default=(
                "You are a helpful voice AI assistant. Keep answers concise."
            )),
            tools=[lookup_weather, get_services, get_price, get_open_hours, list_staff, get_staff_day],  # ‚Üê –Ω–æ–≤—ã–µ —Ç—É–ª–∑—ã
        )


def prewarm(proc: JobProcess):
    proc.userdata["vad"] = silero.VAD.load()
    proc.userdata["barber_db"] = load_barber_db("db/barber")  # ‚Üê –¥–æ–±–∞–≤–∏–ª–∏


async def entrypoint(ctx: JobContext):
    ctx.log_context_fields = {"room": ctx.room.name}

    session = AgentSession(
        # ‚ö†Ô∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –ø—Ä–∏–≤—ã—á–∫–∞ –ø–æ–¥ —Ç–µ–±—è (RU/ES):
        stt=azure.STT(
            speech_key=os.getenv("AZURE_SPEECH_KEY"),
            speech_region=os.getenv("AZURE_SPEECH_REGION", "francecentral"),
            language=["ru-RU"],  # –¥–æ–±–∞–≤—å "es-ES" –ø—Ä–∏ –¥–≤—É—è–∑—ã—á–∏–∏: ["es-ES","ru-RU"]
        ),
        tts=azure.TTS(
            speech_key=os.getenv("AZURE_SPEECH_KEY"),
            speech_region=os.getenv("AZURE_SPEECH_REGION", "francecentral"),
            voice="ru-RU-SvetlanaNeural",
            language="ru-RU",
        ),
        llm=openai.LLM.with_azure(
            azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            api_version=os.getenv("OPENAI_API_VERSION", "2024-10-21"),
            model=os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o"),
            temperature=0.3,
        ),
        turn_detection=MultilingualModel(),
        vad=ctx.proc.userdata["vad"],
        preemptive_generation=True,
        # ‚Üí –≤–∫–ª—é—á–∞–µ–º –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ –æ–∑–≤—É—á–∫–µ (–¥–ª—è –ø–µ—á–∞—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ)
        use_tts_aligned_transcript=True,
    )

    @session.on("agent_false_interruption")
    def _on_agent_false_interruption(ev: AgentFalseInterruptionEvent):
        logger.info("false positive interruption, resuming")
        session.generate_reply(instructions=ev.extra_instructions or NOT_GIVEN)

    usage_collector = metrics.UsageCollector()

    @session.on("metrics_collected")
    def _on_metrics_collected(ev: MetricsCollectedEvent):
        metrics.log_metrics(ev.metrics)
        usage_collector.collect(ev.metrics)

    # --- –õ–û–ì–ò –¢–ï–ö–°–¢–ê –í –†–ï–ê–õ–¨–ù–û–ú –í–†–ï–ú–ï–ù–ò ---
    # 1) STT –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: partial/final
    @session.on("user_input_transcribed")
    def _on_user_input_transcribed(ev):
        tag = "USER(final)" if getattr(ev, "is_final", False) else "USER(partial)"
        logger.info(f"{tag}: {getattr(ev, 'transcript', '')}")

    # 2) –§–∏–Ω–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏—Å—Ç–æ—Ä–∏–∏ (—Å–æ–æ–±—â–µ–Ω–∏–µ —é–∑–µ—Ä–∞/–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —É–∂–µ ¬´–¥–æ–±–∞–≤–ª–µ–Ω–æ¬ª)
    @session.on("conversation_item_added")
    def _on_conversation_item_added(ev):
        item = getattr(ev, "item", None)
        role = getattr(item, "role", None)
        text = getattr(item, "text_content", None)
        if role in ("assistant", "user") and text:
            logger.info(f"{role.upper()}: {text}")

    async def log_usage():
        summary = usage_collector.get_summary()
        logger.info(f"Usage: {summary}")

    ctx.add_shutdown_callback(log_usage)

    # –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é –±–µ—Å–µ–¥—ã –≤ —Ñ–∞–π–ª
    async def _save_history():
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        os.makedirs("logs", exist_ok=True)
        path = f"logs/transcript_{ctx.room.name}_{ts}.json"
        with open(path, "w", encoding="utf-8") as f:
            json.dump(session.history.to_dict(), f, ensure_ascii=False, indent=2)
        logger.info(f"Transcript saved to {path}")
    ctx.add_shutdown_callback(_save_history)

    await session.start(
        agent=Assistant(),
        room=ctx.room,
        room_input_options=RoomInputOptions(
            # –ï—Å–ª–∏ self-hosted ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä noise_cancellation —É–±–µ—Ä–∏
            noise_cancellation=noise_cancellation.BVC(),
        ),
        # ‚Üí —Ç–µ–∫—Å—Ç —Å—Ä–∞–∑—É –≤ –∫–æ–Ω—Å–æ–ª—å, –±–µ–∑ ¬´–ø—Ä–∏–≤—è–∑–∫–∏¬ª –∫ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫—É (–º–µ–Ω—å—à–µ –∑–∞–¥–µ—Ä–∂–∫–∞ –≤—ã–≤–æ–¥–∞)
        room_output_options=RoomOutputOptions(sync_transcription=False),
    )

    # 1) –°—Ç–∏–ª—å —Ä–µ—á–∏ (–ø–æ–¥–±–µ—Ä–∏ –æ–¥–∏–Ω –∏–∑: "customer-service", "assistant", "friendly", "cheerful")
    session.tts.update_options(
        style=StyleConfig(
            style="cheerful",  # üëà –æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ: –±–µ–∑ –¥–µ—Ñ–∏—Å–∞ —á–∞—â–µ –≤—Å–µ–≥–æ
            # role –º–æ–∂–Ω–æ –Ω–µ –∑–∞–¥–∞–≤–∞—Ç—å, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ: role="YoungAdultFemale" –∏ —Ç.–ø. –∑–∞–≤–∏—Å—è—Ç –æ—Ç –≥–æ–ª–æ—Å–∞
            # degree ‚Äî ¬´–Ω–∞—Å–∫–æ–ª—å–∫–æ –≤—ã—Ä–∞–∂–µ–Ω¬ª —Å—Ç–∏–ª—å (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º voice)
            degree=1.0,                # 0.01‚Äì2.0 (–ø—Ä–∏–º–µ—Ä –¥–∏–∞–ø–∞–∑–æ–Ω–∞; —Å–º. –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –≥–æ–ª–æ—Å–æ–º)
        )
    )

    # 2) –ü—Ä–æ—Å–æ–¥–∏—è: —Å–∫–æ—Ä–æ—Å—Ç—å/—Ç–æ–Ω/–≥—Ä–æ–º–∫–æ—Å—Ç—å (SSML-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
    session.tts.update_options(
        prosody=ProsodyConfig(
            rate="fast",    # —á—É—Ç—å –±—ã—Å—Ç—Ä–µ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, +5%..+10%), Prosody rate must be one of 'x-slow', 'slow', 'medium', 'fast', 'x-fast'
            pitch="medium",   # Prosody pitch must be one of 'x-low', 'low', 'medium', 'high', 'x-high
            volume="medium", # Prosody volume must be one of 'silent', 'x-soft', 'soft', 'medium', 'loud', 'x-loud'
        )
    )

    # –ü—Ä–æ–∏–∑–Ω–æ—Å–∏–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –∑–∞–¥–∞–Ω–æ
    greeting = read_text("prompts/greeting.txt")
    if greeting:
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º say(), —á—Ç–æ–±—ã –ø—Ä–æ–∏–∑–Ω–µ—Å—Ç–∏ —Ä–æ–≤–Ω–æ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç, –±–µ–∑ LLM-–ø–µ—Ä–µ–∏–Ω–∞—á–∏–≤–∞–Ω–∏—è
        await session.say(greeting)  # –¢—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π TTS –ø–ª–∞–≥–∏–Ω

    await ctx.connect()


if __name__ == "__main__":
    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint, prewarm_fnc=prewarm))
